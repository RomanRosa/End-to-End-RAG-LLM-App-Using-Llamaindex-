## End to end RAG LLM App Using Llamaindex and OpenAI: Indexing and Querying Multiple PDF's

<div align="center">

<a href="https://www.youtube.com/watch?v=hH4WkgILUD4">
  <img src="http://img.youtube.com/vi/hH4WkgILUD4/0.jpg" alt="End to end RAG LLM App Using Llamaindex and OpenAI: Indexing and Querying Multiple pdf's" width="400" />
</a>

</div>

In this video, we will build an end to end Retrieve and Generate Language Model application using LlamaIndex and OpenAI. 

We will index multiple PDF documents, store the indexes in a vector database, define a frontend search interface to query the index, and use OpenAI's powerful language models to generate relevant summaries by querying the index.

[OpenAI](https://openai.com/) has created groundbreaking language model APIs that can understand language, answer questions, summarize documents etc. 

[LlamaIndex](https://llama.xyz/) builds upon these language models and allows you to index documents, store vector representations and generate answers by querying the vector index.

We will demonstrate:

- Indexing multiple PDF documents 
- Storing indexes in a vector database
- Defining a streamlit frontend to search the index
- Querying the index to generate relevant summaries and answers

Overall, this project shows how you can build powerful generative apps by combining OpenAI APIs with vector indexing techniques provided by LlamaIndex!
